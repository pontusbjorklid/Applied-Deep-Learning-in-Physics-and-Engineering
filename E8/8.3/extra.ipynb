{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot training data predictions vs true\n",
    "n_features = trainX_all.shape[2]\n",
    "predicted_RULs = []\n",
    "true_RULs = []\n",
    "for i in range(6):\n",
    "    unit_data = trainX_all[i].reshape(1, n_past, n_features)  # Reshape to 3D array\n",
    "    predicted_RUL = model.predict(unit_data, verbose = 0, batch_size = 32)\n",
    "    predicted_RULs.append(predicted_RUL.flatten()[0])  # Flatten the prediction\n",
    "    true_RULs.append(trainY_all[i])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(predicted_RULs, label='Predicted RUL')\n",
    "plt.plot(true_RULs, label='True RUL', linestyle='--')\n",
    "plt.title(f'Predicted vs True RUL for Unit 1')\n",
    "plt.xlabel('Section Number')\n",
    "plt.ylabel('RUL')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_RULs = []\n",
    "true_RULs = []\n",
    "for x in range(7):\n",
    "  x += 1\n",
    "  for i in range(300):\n",
    "    if trainX_all[i][0][0] == x:\n",
    "      unit_data = trainX_all[i].reshape(1, n_past, n_features)  # Reshape to 3D array\n",
    "      predicted_RUL = model.predict(unit_data, verbose = 0, batch_size = 32)\n",
    "      predicted_RULs.append(predicted_RUL.flatten()[0])  # Flatten the prediction\n",
    "      true_RULs.append(trainY_all[i])\n",
    "    \n",
    "  plt.figure(figsize=(5, 5))\n",
    "  plt.plot(predicted_RULs, label='Predicted RUL')\n",
    "  plt.plot(true_RULs, label='True RUL', linestyle='--')\n",
    "  plt.title(f'Predicted vs True RUL')\n",
    "  plt.xlabel('Cycle')\n",
    "  plt.ylabel('RUL')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "  predicted_RULs = []\n",
    "  true_RULs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=np.array( true_RULs)\n",
    "splits=[]\n",
    "test2= np.array(predicted_RULs)\n",
    "for i in range(1,len(test)):\n",
    "  if test[i] > test[i-1]:\n",
    "    splits.append(i)\n",
    "\n",
    "test_split = np.split(test, splits)\n",
    "test2_split = np.split(test2, splits)\n",
    "\n",
    "\n",
    "for i in range(len(test2_split)):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(test2_split[i], label='Predicted RUL')\n",
    "    plt.plot(test_split[i], label='True RUL')\n",
    "    plt.title(f'Predicted RUL vs True RUL for Unit {i+1}')\n",
    "    plt.xlabel('Cycle Time')\n",
    "    plt.ylabel('Remaining Useful Life (RUL)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_test_list length == 100.\n",
      "data_test_list first element shape == (31, 19).\n"
     ]
    }
   ],
   "source": [
    "#test data set without labels\n",
    "data_test = pd.read_csv('test_FD001.txt', delimiter=' ', header=None)\n",
    "\n",
    "name_list = ['unit', 'time', 'setting0', 'setting1', 'setting2']\n",
    "for i in range(number_of_sensors):\n",
    "  name_list.append('sensor'+str(i))\n",
    "name_list.append('empty1')\n",
    "name_list.append('empty2')\n",
    "data_test.columns = name_list\n",
    "\n",
    "data_test = data_test.drop(['empty1'], axis=1)\n",
    "data_test = data_test.drop(['empty2'], axis=1)\n",
    "\n",
    "#choose which columns of data you want to keep and which you want to drop.\n",
    "#Training with everything works but might not be the best choice.\n",
    "data_test = data_test.drop(['setting2', 'sensor0','sensor4', 'sensor9', 'sensor15', 'sensor17', 'sensor18'], axis=1)\n",
    "\n",
    "#normalization of the training data on selected sensors and settings\n",
    "columns_to_scale = data_test.columns.drop(['unit', 'time'])\n",
    "scaler = StandardScaler().fit(data_test[columns_to_scale])\n",
    "data_test_scaled = data_test.copy()\n",
    "data_test_scaled[columns_to_scale] = scaler.transform(data_test[columns_to_scale])\n",
    "\n",
    "columns = data_test_scaled.shape[1]\n",
    "\n",
    "##########################################\n",
    "data_test_list = []\n",
    "time_steps_data = np.empty((2, columns))\n",
    "\n",
    "for i in range(1,len(data_test_scaled)):\n",
    "\n",
    "  if i == len(data_test_scaled)-1:\n",
    "    data_test_list.append(time_steps_data)\n",
    "\n",
    "  elif data_test_scaled[\"unit\"][i] != data_test_scaled['unit'][i-1]:\n",
    "    time_steps_data = time_steps_data[1:]\n",
    "    data_test_list.append(time_steps_data)\n",
    "    time_steps_data = np.empty(columns)\n",
    "\n",
    "  time_steps_data = np.vstack((time_steps_data, data_test_scaled.iloc[i]))\n",
    "\n",
    "\n",
    "print('data_test_list length == {}.'.format(len(data_test_list)))\n",
    "print('data_test_list first element shape == {}.'.format(data_test_list[0].shape))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
