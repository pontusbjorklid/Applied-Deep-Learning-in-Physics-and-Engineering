{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise and Lab: Pulse Shape Discrimination**\n",
        "\n",
        "The goal of this exercise is to perform a pulse shape analysis on real data.\n",
        "\n",
        "A scintillation detector is exposed to both neutron and gamma radiation, both emitted from a source places some half meter away from the detector. A detected particle (neutron or gamma) will result in an electrical pulse (a short signal) from the detector. However, the pulse shape of the detector signal depends looks different for both types of particles.\n",
        "\n",
        "Together with the detector pulse, the flight time of the particle from the source to the detector is measured. (More on this in the introductory video for the lab.) Since gammas move at speed of light and neutrons don't, the flight times provide a second way of discriminating between neutrons and gammas, independent of the pulse shapes. Use this information to label the data.\n",
        "\n",
        "We start by downloading a data file. For testing there is a small data set, once everything works, there is more data..."
      ],
      "metadata": {
        "id": "QDEZlaKnTwgD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwJND5agPIUA"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "# The code snippet below is responsible for downloading the dataset\n",
        "# - for example when running via Google Colab.\n",
        "# It is enough to load one of the files below.\n",
        "\n",
        "# Small data file.\n",
        "!gdown https://drive.google.com/uc?id=1Ejrt2O6rRj0N7F29pXxsa-gELsVaGhfA\n",
        "\n",
        "# The small data file is enough to do this exercise but if you want you can also use much more data.\n",
        "# Large data file. Uncomment this line only if you really want to use all data.\n",
        "# !gdown https://drive.google.com/uc?id=1AcMxtW3GFsKpkLqDLwlDxgYFtbtzcrZQ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step will be do load the data into a numpy array and check it, e.g. by looking at some pulses.\n",
        "\n",
        "The data consists of a (high) number of lines, each line representing one pulse."
      ],
      "metadata": {
        "id": "gst-4tDL7Ubb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_raw = np.load('/content/data_small.npy')\n",
        "\n",
        "# Check the size of the data file\n",
        "print(data_raw.shape)\n",
        "# Print the first pulse\n",
        "# print(data[0])"
      ],
      "metadata": {
        "id": "yfu5rAnt6xZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first number in each line is a detector identifier, which we can happily ignore here.\n",
        "\n",
        "The second number is the flight time in nanoseconds, this provides information about the particle type, neutron or gamma.\n",
        "\n",
        "The pulse is sampled at a rate of 1 GHz, so the remaining 512 numbers represent 512 ns of the pulse shape."
      ],
      "metadata": {
        "id": "B5Mv-l8J9tKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the pulse shape part of the data\n",
        "pulses = data_raw[:,2:]\n",
        "# Prepare a figure and plot some pulses\n",
        "print(pulses.shape)\n",
        "fig, ax = plt.subplots(figsize=(16,8))\n",
        "ax.plot(pulses[0])\n",
        "ax.plot(pulses[10])\n",
        "ax.plot(pulses[100])\n",
        "ax.plot(pulses[1000])\n",
        "ax.plot(pulses[10000])\n",
        "ax.set_xlabel(\"time [ns]\")\n",
        "ax.set_ylabel(\"amplitude [ADC counts]\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cbdt8fXG_2J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now extract the flight times."
      ],
      "metadata": {
        "id": "opiSDee2C2uN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "times = data_raw[:,1]\n",
        "print('Flight times between', times.min(), 'and', times.max(), 'nanoseconds.')"
      ],
      "metadata": {
        "id": "-d803g6qREIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative flight times (also called times of flight, tof) are okay (for random coincidences), but we will restrict their range before plotting:"
      ],
      "metadata": {
        "id": "7PoquvPWXAOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_tof = -20\n",
        "max_tof = 40\n",
        "times = times[(times>=min_tof) & (times<=max_tof)]\n",
        "# Now create a figure\n",
        "fig, ax  = plt.subplots(figsize=(16,8))\n",
        "ax.hist(times, bins=240)   # high resolution: 4 bins per nanosecond\n",
        "ax.set_xlabel('Flight time [ns]')\n",
        "ax.set_ylabel('Counts')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_vGqhJdWYVhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The flight time spectrum shows a gamma peak at around 0 ns and a neutron peak at around 10 to 20 ns.\n",
        "You can now define flight time ranges within which you will accept gammas and neutrons. Please adjust the numbers below according to your data and your liking.\n",
        "During the exercise class, we will discuss how the choice of the limits affects your results."
      ],
      "metadata": {
        "id": "uH7-WXaTckHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gamma_min_tof =\n",
        "gamma_max_tof =\n",
        "neutron_min_tof =\n",
        "neutron_max_tof =\n",
        "\n",
        "gammadata = data_raw[(data_raw[:,1] >= gamma_min_tof) & (data_raw[:,1] <= gamma_max_tof)]\n",
        "gammapulses = gammadata[:,2:]\n",
        "print('Gammas:  ', gammapulses.shape)\n",
        "\n",
        "neutrondata = data_raw[(data_raw[:,1] >= neutron_min_tof) & (data_raw[:,1] <= neutron_max_tof)]\n",
        "neutronpulses = neutrondata[:,2:]\n",
        "print('Neutrons:', neutronpulses.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "XayqSsFdYCc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You now have two arrays with pulse shapes, one with only gammas (according to the flight times) and one with only neutrons (again, according to the flight times). Each array contains a large number of pulse shapes, each pulse consists of 512 detector readings.\n",
        "\n",
        "Let's start preparing the data for the training of a neural network.\n",
        "\n"
      ],
      "metadata": {
        "id": "w77F2ABpratI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make a combined data set containing both pulse types\n",
        "data = np.vstack((gammapulses, neutronpulses))\n",
        "labels = np.zeros(len(data), dtype=int)\n",
        "labels[:len(gammapulses)] = 1\n",
        "# gammas are labelled as 1, and neutrons are labelled as 0\n",
        "\n",
        "# normalize the data\n",
        "# TODO\n",
        "\n",
        "\n",
        "samples_per_pulse = len(data[0])\n",
        "\n",
        "# in case you use a CNN architecture, we need to add an empty axis.\n",
        "data = data[:,:, np.newaxis]\n",
        "\n",
        "# before we split up the dataset into training, validation and test data set, we need to shuffle the events\n",
        "# otherwise we end up having only one type of event in our validation and test data sets.\n",
        "np.random.seed(1234)\n",
        "shuffle_indices = np.arange(0, len(data), dtype=int)\n",
        "np.random.shuffle(shuffle_indices)\n",
        "data = data[shuffle_indices]\n",
        "labels = labels[shuffle_indices]"
      ],
      "metadata": {
        "id": "NbGx9e6I12s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot a few events\n",
        "for i in range(10):\n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    ax.plot(data_train[i,:,0])\n",
        "    ax.set_title(f\"label {labels_train[i]}\")\n",
        "    ax.set_xlabel(\"time [ns]\")\n",
        "    ax.set_ylabel(\"normalized amplitude\")\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close(\"all\")"
      ],
      "metadata": {
        "id": "x0AmWTSz3wi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path = os.path.join('saved_models')\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)"
      ],
      "metadata": {
        "id": "VNFBOqd13BMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can define the neural network and train it."
      ],
      "metadata": {
        "id": "u2osqqodb5Ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first the usual imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Conv1D, Flatten, Dropout\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, AveragePooling1D, Input, Flatten, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "import pickle\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# if you use a fully connected network (dense) you need to flatten the input data first. You can implement this\n",
        "# as a network layer:\n",
        "# model.add(Flatten(input_shape=(samples_per_pulse, 1)))\n",
        "\n",
        "# if you use a convlutional layer first, you can directly use the input data\n",
        "# model.add(Conv1D(, , padding=, activation=, input_shape=(samples_per_pulse, 1)))\n",
        "\n"
      ],
      "metadata": {
        "id": "qfKOtOU73_oB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}